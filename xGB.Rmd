---
title: "xGB model"
output: html_document
date: "2025-02-09"
---

```{r setup, include=FALSE}
### xGB% model
## separate models with & without location
```

```{r}
## import packages

library(data.table)
library(ggplot2)
library(xgboost)
library(caret)
library(stats)
library(dplyr)
library(pROC)

```

```{r}
## loading df and viewing columns

df <- read.csv("~/Desktop/d1_trackman.csv")

print(df)

print(colnames(df))

```

```{r}
## drop duplicates

df <- df %>% distinct()

```

```{r}
## selecting needed columns

df <- df %>% select(PitcherId, Date, PitcherThrows, BatterId, Balls, Strikes, TaggedPitchType, PitchCall, KorBB, TaggedHitType, PlayResult, RelSpeed, SpinAxis, RelHeight, RelSide, Extension, InducedVertBreak, HorzBreak, PlateLocHeight, PlateLocSide, Angle)

```

```{r}
## modifying df to only have bip 

df <- df %>% filter(PitchCall == "InPlay")

```


```{r}
## only including if pitcher throws = right or left

df <- df %>%
  filter(!(PitcherThrows %in% c("Both", "Undefined")) & !is.na(PitcherThrows))

```

```{r}
## adjusting spin axis for lhp

df <- df %>%
  mutate(SpinAxis = ifelse(PitcherThrows == "Left", 360 - SpinAxis, SpinAxis))

```

```{r}
## absolute value of rel side and horz break for lhp

df <- df %>%
  mutate(
    RelSide = ifelse(PitcherThrows == "Left", abs(RelSide), RelSide),
    HorzBreak = ifelse(PitcherThrows == "Left", abs(HorzBreak), HorzBreak)
  )

```

```{r}
## distinct pitch types and renaming into groups

df %>% count(TaggedPitchType)

df <- df %>%
  filter(!(TaggedPitchType %in% c("Other", "Undefined", ",")))

df <- df %>%
  mutate(TaggedPitchType = case_when(
    TaggedPitchType %in% c("ChangeUp", "Knuckleball", "Splitter") ~ "Offspeed",
    TaggedPitchType %in% c("Curveball") ~ "Curveball",
    TaggedPitchType %in% c("Fastball", "FourSeamFastBall") ~ "Fastball",
    TaggedPitchType %in% c("OneSeamFastball", "Sinker", "TwoSeamFastBall") ~ "Sec_Fastball",
    TaggedPitchType %in% c("Slider") ~ "Slider",
    TaggedPitchType %in% c("Cutter") ~ "Cutter",
    TRUE ~ TaggedPitchType  
  ))


```

```{r}
## GB indicator column

df <- df %>%
  mutate(GB = case_when(
    TaggedHitType %in% c("GroundBall", "Groundball") ~ 1,
    TRUE ~ 0
  ))

```

```{r}
## ensuring gb column is numeric 

df <- df %>% mutate(GB = as.numeric(GB))

```


```{r}
## creating separate df for each pitch type and printing dimensions

fb_df <- df %>%
  filter(TaggedPitchType == "Fastball")
dim(fb_df)

sec_fb_df <- df %>%
  filter(TaggedPitchType == "Sec_Fastball")
dim(sec_fb_df)

cut_df <- df %>%
  filter(TaggedPitchType == "Cutter")
dim(cut_df)

offs_df <- df %>%
  filter(TaggedPitchType == "Offspeed")
dim(offs_df)

cb_df <- df %>%
  filter(TaggedPitchType == "Curveball")
dim(cb_df)

sl_df <- df %>%
  filter(TaggedPitchType == "Slider")
dim(sl_df)

```

```{r}
## setting features and target for location incorporated model

features <- c("RelSpeed", "SpinAxis", "RelHeight", "RelSide", 
              "InducedVertBreak", "HorzBreak", "PlateLocHeight", "PlateLocSide")
target <- "GB"

```

```{r}
## setting features for no location model

no_loc_features <- c("RelSpeed", "SpinAxis", "RelHeight", "RelSide", 
              "InducedVertBreak", "HorzBreak")

```

```{r}
#### FB XGBOOST: WITH LOCATION

set.seed(42)

# Prepare Data
train_index <- createDataPartition(fb_df$GB, p = 0.8, list = FALSE)

train_data <- fb_df[train_index, ]
test_data <- fb_df[-train_index, ]

train_matrix <- as.matrix(train_data[, features])
test_matrix <- as.matrix(test_data[, features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

best_params <- list(
  max_depth = 6,
  eta = 0.05,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV final results 
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Make Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Feature Importance
importance <- xgb.importance(feature_names = features, model = xgb_model)
xgb.plot.importance(importance)

# Brier Score
brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

print(mean(pred_probs))
print(sd(pred_probs))
print(mean(fb_df$GB))


```

```{r}
### FB XGBOOST: NO LOCATION

set.seed(42)

# Split Data
train_index <- createDataPartition(fb_df$GB, p = 0.8, list = FALSE)

train_data <- fb_df[train_index, ]
test_data <- fb_df[-train_index, ]

train_matrix <- as.matrix(train_data[, no_loc_features])
test_matrix <- as.matrix(test_data[, no_loc_features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

best_params <- list(
  max_depth = 7,
  eta = 0.05,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100 

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final cv results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Make Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Feature Importance
importance <- xgb.importance(feature_names = no_loc_features, model = xgb_model)
xgb.plot.importance(importance)

# Brier Score
brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

print(mean(pred_probs))
print(sd(pred_probs))
print(mean(fb_df$GB))


```

```{r}
## save fb model (without location)

model <- "~/Desktop/fb_exgb.rds"

saveRDS(xgb_model, model)

print(paste("Model saved to:", model))

```


```{r}

#### SECONDARY FB XGBOOST: WITH LOCATION

set.seed(42)

# Split Data
train_index <- createDataPartition(sec_fb_df$GB, p = 0.8, list = FALSE)
train_data <- sec_fb_df[train_index, ]
test_data <- sec_fb_df[-train_index, ]

train_matrix <- as.matrix(train_data[, features])
test_matrix <- as.matrix(test_data[, features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 6,
  eta = 0.04,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Make Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Brier Score
brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(sec_fb_df$GB), 4)))


```


```{r}
### SECONDARY FASTBALL XGBOOST: NO LOCATION

set.seed(42)

# Split Data
train_index <- createDataPartition(sec_fb_df$GB, p = 0.8, list = FALSE)
train_data <- sec_fb_df[train_index, ]
test_data <- sec_fb_df[-train_index, ]

train_matrix <- as.matrix(train_data[, no_loc_features])
test_matrix <- as.matrix(test_data[, no_loc_features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 7,
  eta = 0.03,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100 

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Make Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Brier Score
brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = no_loc_features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(sec_fb_df$GB), 4)))


```

```{r}
## save secondary fb model to desktop (non-location version)

model <- "~/Desktop/sec_fb_exgb.rds"

saveRDS(xgb_model, model)

print(paste("Model saved to:", model))
```

```{r}

#### CUTTER XGBOOST: WITH LOCATION

set.seed(42)

# Split Data
train_index <- createDataPartition(cut_df$GB, p = 0.8, list = FALSE)
train_data <- cut_df[train_index, ]
test_data <- cut_df[-train_index, ]

train_matrix <- as.matrix(train_data[, features])
test_matrix <- as.matrix(test_data[, features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 6,
  eta = 0.02,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Make Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Brier Score
brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(cut_df$GB), 4)))


```


```{r}
#### CUTTER XGBOOST: NO LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(cut_df$GB, p = 0.8, list = FALSE)
train_data <- cut_df[train_index, ]
test_data <- cut_df[-train_index, ]

train_matrix <- as.matrix(train_data[, no_loc_features])
test_matrix <- as.matrix(test_data[, no_loc_features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 7,
  eta = 0.05,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = no_loc_features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(cut_df$GB), 4)))




```

```{r}
## saving no location cutter model to desktop 

model <- "~/Desktop/ct_exgb.rds"

saveRDS(xgb_model, model)

print(paste("Model saved to:", model))
```


```{r}

#### OFFSPEED XGBOOST: WITH LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(offs_df$GB, p = 0.8, list = FALSE)
train_data <- offs_df[train_index, ]
test_data <- offs_df[-train_index, ]

train_matrix <- as.matrix(train_data[, features])
test_matrix <- as.matrix(test_data[, features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 6,
  eta = 0.04,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100 

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(offs_df$GB), 4)))



```


```{r}

#### OFFSPEED XGBOOST: WITHOUT LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(offs_df$GB, p = 0.8, list = FALSE)
train_data <- offs_df[train_index, ]
test_data <- offs_df[-train_index, ]

train_matrix <- as.matrix(train_data[, no_loc_features])
test_matrix <- as.matrix(test_data[, no_loc_features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 4,
  eta = 0.04,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100 

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = no_loc_features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(offs_df$GB), 4)))


```
```{r}
## saving no location offspeed model to desktop 

model <- "~/Desktop/os_exgb.rds"

saveRDS(xgb_model, model)

print(paste("Model saved to:", model))
```

```{r}

#### CURVEBALL XGBOOST: WITH LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(cb_df$GB, p = 0.8, list = FALSE)
train_data <- cb_df[train_index, ]
test_data <- cb_df[-train_index, ]

train_matrix <- as.matrix(train_data[, features])
test_matrix <- as.matrix(test_data[, features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 4,
  eta = 0.06,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(cb_df$GB), 4)))


```


```{r}

#### CURVEBALL XGBOOST: WITHOUT LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(cb_df$GB, p = 0.8, list = FALSE)
train_data <- cb_df[train_index, ]
test_data <- cb_df[-train_index, ]

train_matrix <- as.matrix(train_data[, no_loc_features])
test_matrix <- as.matrix(test_data[, no_loc_features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 4,
  eta = 0.04,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

# Feature Importance
importance <- xgb.importance(feature_names = no_loc_features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(cb_df$GB), 4)))

```

```{r}
## saving no location curveball model to desktop

model <- "~/Desktop/cb_exgb.rds"

saveRDS(xgb_model, model)

print(paste("Model saved to:", model))
```


```{r}

#### SLIDER XGBOOST: WITH LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(sl_df$GB, p = 0.8, list = FALSE)
train_data <- sl_df[train_index, ]
test_data <- sl_df[-train_index, ]

train_matrix <- as.matrix(train_data[, features])
test_matrix <- as.matrix(test_data[, features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 6,
  eta = 0.08,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100 

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Feature Importance
importance <- xgb.importance(feature_names = features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(sl_df$GB), 4)))


```

```{r}

#### SLIDER XGBOOST: NO LOCATION 

set.seed(42)

# Split Data
train_index <- createDataPartition(sl_df$GB, p = 0.8, list = FALSE)
train_data <- sl_df[train_index, ]
test_data <- sl_df[-train_index, ]

train_matrix <- as.matrix(train_data[, no_loc_features])
test_matrix <- as.matrix(test_data[, no_loc_features])

y_train <- train_data$GB
y_test <- test_data$GB

dtrain <- xgb.DMatrix(data = train_matrix, label = y_train)
dtest <- xgb.DMatrix(data = test_matrix, label = y_test)

# parameters
best_params <- list(
  max_depth = 7,
  eta = 0.08,
  subsample = 0.8,
  colsample_bytree = 0.8,
  objective = "binary:logistic",
  eval_metric = "logloss"
)

best_nrounds <- 100  

# Train Final Model 
xgb_model <- xgb.train(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# CV for final results
cv_results_final <- xgb.cv(
  params = best_params,
  data = dtrain,
  nrounds = best_nrounds,
  nfold = 5,
  verbose = 0
)

# Print final CV results
print(paste("Final Cross-Validated Logloss:", round(min(cv_results_final$evaluation_log$test_logloss_mean), 4)))

# Predictions
pred_probs <- predict(xgb_model, dtest)
preds <- ifelse(pred_probs > 0.5, 1, 0)

# Evaluation
accuracy <- mean(preds == y_test)
print(paste("Accuracy:", round(accuracy, 4)))

brier_score <- mean((pred_probs - y_test)^2)
print(paste("Brier Score:", round(brier_score, 4)))

conf_matrix <- table(Predicted = preds, Actual = y_test)
print(conf_matrix)

# Feature Importance
importance <- xgb.importance(feature_names = no_loc_features, model = xgb_model)
xgb.plot.importance(importance)

# Probability Distribution
hist(pred_probs, breaks = 30, main = "GB Probability Distribution", xlab = "Probability")

# Mean of Predictions & Actuals
print(paste("Mean Predicted Probability:", round(mean(pred_probs), 4)))
print(sd(pred_probs))
print(paste("Mean Actual GB:", round(mean(sl_df$GB), 4)))


```

```{r}
## saving no location sl model to desktop

model <- "~/Desktop/sl_exgb.rds"

saveRDS(xgb_model, model)

print(paste("Model saved to:", model))
```




